---
title: "Determine This"
author: "Olusoji Oluwafemi Daniel"
date: "3 April 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(tidyverse)
library(ggmap)
library(CAMAN)
library(rjags)
library(runjags)
library(gamlss)
library(psych)
library(geoR)
library(ggmap)


alex_data <- read_csv("Data/data.csv", col_names = T)
#names(alex_data)


```

## Exploratory Analysis and Data Cleaning

### Spatial Plot of Measurement Locations

We make a spatial point plot of the farms and their locations.

```{r exp1}
lat <- 7.451099
lon <- 3.896599

ggplot(data = alex_data, aes(x = Longitude, y = latitude)) + 
  geom_point(size = 2) + theme_bw() + geom_jitter(width = 0.60) + 
  labs(x = "Longitude", y = "Latitude")
```

Based on the above plot, one can clearly see three clusters based on the locations of the farms where the samples were taken. The first cluster of farms occurs at latitude below 7.450, the second cluster of farms are at latitude above 7.450 but lesser than latitude 7.475, while the thired cluster of farms occurs above the last latitude.

### Cluster Division

We divide the dataset into three clusters based on the findings above.

```{r cluster_division}
alex_data <- alex_data %>% dplyr::mutate(Id = case_when(
  latitude < 7.4525 ~ 1,
  latitude >= 7.4525 & latitude <= 7.475 ~ 2,
  latitude > 7.475 ~ 3
), M.C_logit = psych::logit(M.C) ) %>% dplyr::mutate(Id2 = as.factor(Id))

 alex_data %>% ggplot(data = ., aes(x = Longitude, y = latitude, 
                                              color = Id2)) + 
  geom_point(size = 2) + theme_bw() + labs(color = "Cluster_Id")
```

### Relationships Between Variables

####  Thermal.C

```{r thermal.c}
alex_data %>% ggplot(aes(y = Thermal.C, x = Temp)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Temperature", color = "Cluster_Id")

alex_data %>% ggplot(aes(y = Thermal.C, x = M.C)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Moisture Content", color = "Cluster_Id")

alex_data %>% ggplot(aes(y = Thermal.C, x = Elevation)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Elevation", color = "Cluster_Id")
```

####  Thermal.D

```{r thermal.d}
alex_data %>% ggplot(aes(y = Thermal.D, x = Temp)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Temperature", color = "Cluster_Id")

alex_data %>% ggplot(aes(y = Thermal.D, x = M.C)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Moisture Content", color = "Cluster_Id")

alex_data %>% ggplot(aes(y = Thermal.D, x = Elevation)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Elevation", color = "Cluster_Id")
```

####  S.H

```{r s.h}
alex_data %>% ggplot(aes(y = S.H, x = Temp)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Temperature", color = "Cluster_Id")

alex_data %>% ggplot(aes(y = S.H, x = M.C)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Moisture Content", color = "Cluster_Id")

alex_data %>% ggplot(aes(y = S.H, x = Elevation)) + 
  geom_point(aes(color = Id2), size = 1.5) + theme_bw() + 
  labs(x = "Elevation", color = "Cluster_Id")
```


##  Exploratory Modelling

We initially choose to treat this data as if it were clustered, since initial explorations reveals the presence of 3 clusters. It should be noted here that we lump up both the spatial and intra-cluster correlation into the intra-cluster correlation. Before we go ahead to fit these models, we would like to figure the best fitting distribution to each of the response variable.

### THERMAL C

```{r, message=FALSE, results='hide'}
families_thermalC <- c("NO", "GA", "LOGNO", "IGAMMA")
AICs <- sapply(families_thermalC, function(x) {
  AIC(gamlss(Thermal.C~ Elevation + Temp + M.C, 
           data = alex_data, family = x))
})
```



```{r}
knitr::kable(data.frame(Distribution = families_thermalC, AICs = AICs), 
             row.names = F, align = 'c')

```

The *Normal* distribution has the lowest AIC here, hence it is selected as the distribution of choice.

### S.H

```{r, message=FALSE, results='hide'}
families_S.H <- c("NO", "GA", "LOGNO", "IGAMMA")
AICs <- sapply(families_S.H, function(x) {
  AIC(gamlss(S.H~ Elevation + Temp + M.C, 
           data = alex_data, family = x))
})
```


```{r}
knitr::kable(data.frame(Distribution = families_S.H, AICs = AICs), 
             row.names = F, align = 'c')

```

The *Inverse Gamma* distribution has the lowest AIC here but since its gain in AIC is comparable to the *Log-normal distribution*, the log-normal distribution is selected.

### ThermalD

```{r, message=FALSE, results='hide'}
families_thermalD <- c("NO", "GA", "LOGNO", "IGAMMA")
AICs <- sapply(families_thermalD, function(x) {
  AIC(gamlss(Thermal.D~ Elevation + Temp + M.C, 
           data = alex_data, family = x))
})
```



```{r}
knitr::kable(data.frame(Distribution = families_thermalD, AICs = AICs), 
             row.names = F, align = 'c')

```

The *Normal* distribution has the lowest AIC here, hence it should selected as the distribution of choice. However, the range of the dataset calls for concern here as only one data point equals 1. Therefore, We will try to fit Thermal.D with *Beta* distribution and logit transformation of Thermal Diffusivity  with *normal* distributions respectively without the observation in question.

```{r, message=FALSE, results='hide'}
alex_data1 <- alex_data[-17, ]
aic_beta <- AIC(gamlss(Thermal.D~ Elevation + Temp + M.C, 
           data = alex_data1, family = BE))
```


```{r, message=FALSE, results='hide'}
Thermal.D_logit <- psych::logit(alex_data1$Thermal.D)
aic_logitnorm <- AIC(gamlss(Thermal.D_logit~ Elevation + Temp + M.C, 
           data = alex_data1, family = NO))
aic_norm <- AIC(gamlss(Thermal.D ~ Elevation + Temp + M.C, 
           data = alex_data1, family = NO))
```

```{r}
knitr::kable(data.frame(Distributions = c("NO[logit]", "NO[-17]", "Beta"), 
                        AICs = c(aic_logitnorm, aic_norm, aic_beta)),
             row.names = F, align = 'c')
```
Fitting a *Beta* distribution without the observation under scrutiny results in a negative AIC as well but one that is smaller than that of the normal distribution. Also, the AIC for model $NO[17]$ is quite close to that of the model with the full data above. This hints at this observation not causing a significant change in inference, hence the analysis could be continued without this observation. This would then mean that the *Beta* distribution would be the most ideal since both the logit transformed and the *NO[17]* versions have larger AICs.

## Bayesian Linear Regression (without clustering and heteroscedasticity)

### Thermal.C

```{r, Thermal.C}
###normal assumption for Thermal.C
cat("
    model{
    #### #the normal likelihood for the data
    for(i in 1: N) {
      mu[i] <-  beta[1] + beta[2]*Elevation[i] + beta[3]*Temp[i] + beta[4]*MC[i]
      y[i] ~ dnorm(mu[i], tau)
    
      res[i] <- y[i]-mu[i]
}	
    
    #priors for the population parameters
    #variance
    tau <- pow(sigma_y, -2) #converting a precision
    sigma_y ~ dunif(0, 20) #sampling a standard deviation
    
    #prior for the betas
    for(i in 1:4) {
    beta[i] ~ dnorm(0.0, 1.0E-5)
    }
    
    
}",
    file = "ThermalC_bayesian.bug")

thermalCdata <- list(N = nrow(alex_data),
                     y = alex_data$Thermal.C,
                     Elevation = alex_data$Elevation,
                     Temp = alex_data$Temp,
                     MC = alex_data$M.C
)

thermalCini <- list(list(beta = c(0.9, 0.002, 0.03, 1.59), sigma_y = 0.12),
                    list(beta = c(0.9, 0.002, 0.03, 1.59)/2, sigma_y = 0.12/2))

thermalC_bayesian <- run.jags(model = "ThermalC_bayesian.bug",
                              monitor=c("beta", "sigma_y","res"),
                              data = thermalCdata, inits = thermalCini, n.chains = 2,
                              sample = 30000, burnin = 20000,
                              thin = 15, adapt = 40000,
                              method = "rjags", jags.refresh = 10)

###The posterior summary checks?
plot(thermalC_bayesian, "trace", vars = c("beta", "sigma_y"))
plot(thermalC_bayesian, "autocorr", vars = c("beta", "sigma_y"))
dic_thermalC<- extract(thermalC_bayesian, what = "dic")
dic_thermalC

```
```{r}
knitr::kable(thermalC_bayesian$summaries[1:5, c(1:5)])
```

###S.H

```{r, SH}
###normal assumption for Thermal.C
cat("
    model{
    #### #the normal likelihood for the data
    for(i in 1: N) {
      mu[i] <-  beta[1] + beta[2]*Elevation[i] + beta[3]*Temp[i] + beta[4]*MC[i]
      y[i] ~ dlnorm(mu[i], tau)
    
      res[i] <- y[i]-mu[i]
}	
    
    #priors for the population parameters
    #variance
    tau <- pow(sigma_y, -2) #converting a precision
    sigma_y ~ dunif(0, 20) #sampling a standard deviation
    
    #prior for the betas
    for(i in 1:4) {
    beta[i] ~ dnorm(0.0, 1.0E-5)
    }
    
    
}",
    file = "ThermalC_bayesian.bug")

thermalCdata <- list(N = nrow(alex_data),
                     y = alex_data$S.H,
                     Elevation = alex_data$Elevation,
                     Temp = alex_data$Temp,
                     MC = alex_data$M.C
)

thermalCini <- list(list(beta = c(0.9, 0.002, 0.03, 1.59), sigma_y = 0.12),
                    list(beta = c(0.9, 0.002, 0.03, 1.59)/2, sigma_y = 0.12/2))

SH_bayesian <- run.jags(model = "ThermalC_bayesian.bug",
                              monitor=c("beta", "sigma_y","res"),
                              data = thermalCdata, inits = thermalCini, n.chains = 2,
                              sample = 30000, burnin = 20000,
                              thin = 15, adapt = 40000,
                              method = "rjags", jags.refresh = 10)

###The posterior summary checks?
plot(SH_bayesian, "trace", vars = c("beta", "sigma_y"))
plot(SH_bayesian, "autocorr", vars = c("beta", "sigma_y"))
dic_SH<- extract(SH_bayesian, what = "dic")
dic_SH
```
```{r}
knitr::kable(SH_bayesian$summaries[1:5, c(1:5)])

 
```

## Bayesian random effect model for MC (spatial correlation treated via accounting for clustering) 

### Thermal.C

```{r, Thermal.C2}
#Bayesian random effect model for Thermal C (spatial correlation treated via accounting for clustering)
alex_data <- alex_data[order(alex_data$Id),]
#normal assumption for thermal C
cat("
    model{
    #### #the normal likelihood for the data
    for(i in 1: N){
      #you didn't add the random effect b[Id[i]]
      mu[i] <-  beta[2]*Elevation[i] + beta[3]*Temp[i] + beta[4]*MC[i] + 
                b[Id[i]]
    
      y[i] ~ dnorm(mu[i], tau)
      res[i] <- y[i]-mu[i]
    }
    
    #the cluster random effects
    for(j in 1:J){
      b[j] ~ dnorm(beta[1], tau.b)
    }
    
    #priors for the population parameters
    #variance
    tau <- pow(sigma_y, -2) #converting a precision
    sigma_y ~ dunif(0, 20) #sampling a standard deviation
    
    #priors for the population parameters
    #prior for the betas
    for(i in 1:4){
      beta[i] ~ dnorm(0.0, 1.0E-5)
    }
    
    #prior for the random effect parameters
    #variance between clusters
    tau.b <- pow(sigma.b, -2) #converting it to a precision
    sigma.b ~ dunif(0, 20) #sampling a standard deviation
    
    ###Intra cluster correlation
  
    icc <- sigma.b / (sigma.b + sigma_y)
    
    
    }", file =  "ThermalC_bayesian.bug")

thermalCdata <- list(N = nrow(alex_data),
                     Id = alex_data$Id,
                     y = alex_data$Thermal.C,
                     Elevation = alex_data$Elevation,
                     Temp = alex_data$Temp,
                     MC = alex_data$M.C,
                     J = length(unique(alex_data$Id))
)

thermalCini <- list(list(beta = c(0.9, 0.002, 0.03, 1.59), sigma_y=0.12, 
                         sigma.b = 0.12),
                    list(beta = c(0.9, 0.002, 0.03, 1.59)/2, sigma_y=0.12/2, 
                         sigma.b = 0.12/2))

thermalC_bayesian <- run.jags(model =  "ThermalC_bayesian.bug",
                              monitor=c("beta", "sigma_y", "sigma.b","icc","res"),
                              data = thermalCdata, inits = thermalCini, 
                              n.chains = 2,
                              sample = 50000, burnin = 50000,
                              thin = 15, adapt = 40000,
                              method = "rjags", jags.refresh = 10)

###The posterior summary checks?
plot(thermalC_bayesian, "trace", vars = c("beta", "sigma_y","sigma.b","icc"))
plot(thermalC_bayesian, "autocorr", vars = c("beta", "sigma_y","sigma.b","icc"))
dic_thermalC<- extract(thermalC_bayesian, what = "dic")
dic_thermalC
```
```{r}
knitr::kable(thermalC_bayesian$summaries[1:7, c(1:5)])
```

###SH

```{r, S.H2}
#Bayesian random effect model for S.H (spatial correlation treated via accounting for clustering)
alex_data <- alex_data[order(alex_data$Id),]
#Lognormal assumption for S.H
cat("
    model{
    #### #the normal likelihood for the data
    for(i in 1: N){
      
      mu[i] <-  beta[2]*Elevation[i] + beta[3]*Temp[i] + beta[4]*MC[i] + 
                b[Id[i]]
    
      y[i] ~ dlnorm(mu[i], tau)
      res[i] <- y[i]-mu[i]
    }
    
    #the cluster random effects
    for(j in 1:J){
      b[j] ~ dnorm(beta[1], tau.b)
    }
    
    #priors for the population parameters
    #variance
    tau <- pow(sigma_y, -2) #converting a precision
    sigma_y ~ dunif(0, 20) #sampling a standard deviation
    
    #priors for the population parameters
    #prior for the betas
    for(i in 1:4){
      beta[i] ~ dnorm(0.0, 1.0E-5)
    }
    
    #prior for the random effect parameters
    #variance between clusters
    tau.b <- pow(sigma.b, -2) #converting it to a precision
    sigma.b ~ dunif(0, 20) #sampling a standard deviation
    
    ###Intra cluster correlation
  
    icc <- sigma.b / (sigma.b + sigma_y)
    
    
    }", file =  "ThermalC_bayesian.bug")

thermalCdata <- list(N = nrow(alex_data),
                     Id = alex_data$Id,
                     y = alex_data$S.H,
                     Elevation = alex_data$Elevation,
                     Temp = alex_data$Temp,
                     MC = alex_data$M.C,
                     J = length(unique(alex_data$Id))
)

thermalCini <- list(list(beta = c(0.9, 0.002, 0.03, 1.59), sigma_y=0.12, 
                         sigma.b = 0.12),
                    list(beta = c(0.9, 0.002, 0.03, 1.59)/2, sigma_y=0.12/2, 
                         sigma.b = 0.12/2))

SH1_bayesian <- run.jags(model =  "ThermalC_bayesian.bug",
                              monitor=c("beta", "sigma_y", "sigma.b","icc","res"),
                              data = thermalCdata, inits = thermalCini, 
                              n.chains = 2,
                              sample = 50000, burnin = 50000,
                              thin = 15, adapt = 40000,
                              method = "rjags", jags.refresh = 10)

###The posterior summary checks?
plot(SH1_bayesian, "trace", vars = c("beta", "sigma_y","sigma.b","icc"))
plot(SH1_bayesian, "autocorr", vars = c("beta", "sigma_y","sigma.b","icc"))
dic_SH1<- extract(SH1_bayesian, what = "dic")
dic_thermalC
```
```{r}
knitr::kable(SH1_bayesian$summaries[1:7, c(1:5)])
```

### Bayesian Linear Regression  of Thermal.D (without clustering, missing observation and no heteroscedasticity)
```{r, Thermal.D}
##The Beta regression approach is to reparameterize in terms of mu and phi where mu will be equivalent to y_hat that we predict.In this parameterization you will have alpha=mu*phi and Beta=(1-mu)*phi. You can model mu as the logit of the linear combination
#Bayesian Linear Regression (without clustering and heteroscedasticity)
#normal assumption for Thermal.C
cat("
    model{
    #### #the normal likelihood for the data
    for(i in 1: N){
    y[i] ~ dbeta(alpha[i], beta[i])
    alpha[i]= mu[i]*phi
    beta[i]=(1-mu[i])*phi
    logit(mu[i])=b[1] + b[2]*Elevation[i] + b[3]*Temp[i] + b[4]*MC[i]

    }
    
    #priors for the population parameters
   phi~dgamma(0.1,0.1)
    
    #prior for the betas
    for(i in 1:4){
    b[i] ~ dnorm(0.0, 1.0E-5)
    }
    
    }",
    file = "C:/Users/user/Documents/kas/sp/ThermalC_bayesian.bug")

thermalDdata <- list(N = nrow(alex_data1),
                     y = alex_data1$Thermal.D,
                     Elevation = alex_data1$Elevation,
                     Temp = alex_data1$Temp,
                     MC = alex_data1$M.C
)

thermalDini <- list(list(b = c(0.9, 0.002, 0.03, 1.59), phi = 0.12),
                    list(b = c(0.9, 0.002, 0.03, 1.59)/2, phi = 0.12/2))

thermalD_bayesian <- run.jags(model = "C:/Users/user/Documents/kas/sp/ThermalC_bayesian.bug",
                              monitor=c("b", "phi"),
                              data = thermalDdata, inits = thermalDini, n.chains = 2,
                              sample = 30000, burnin = 20000,
                              thin = 15, adapt = 40000,
                              method = "rjags", jags.refresh = 10)
thermalD_bayesian
```

##Variogram for the Reponse Variables
### Variogram for Thermal Diffusivity
```{r,Thermal Diffusivity Variogram}
##The Residuals extracted from the Model
TDres=thermalC_bayesian$summaries[8:47, c(4:4)]
##We use the residuals to fit a variogram to check for the spatial dependency
res.geoSH <- as.geodata(cbind(alex_data$Longitude,alex_data$latitude,TDres))
vv <- variog(res.geoSH)
print(plot(vv, type="p",pch=19, col = 2,cex.lab = 1.3,
           ylab = expression(v(u)), lwd = 2 ))  

set.seed(123)
for(i in 1:5000){
  presSh <- sample(TDres)
  pres.geoSh <- as.geodata(cbind(alex_data$Longitude,alex_data$latitude,presSh))
  pvariosh <- variog(pres.geoSh)
  print(lines(pvariosh$u, pvariosh$v, pch = 19, col = "gray"))
}
lines(vv$u, vv$v, pch = 19, col = 2, lwd = 2)
```
I need an explanation to it.

###Variogram to Specific Heat
```{r,Specific Heat Variogram}
##The Residuals extracted from the Model
SHres=SH_bayesian$summaries[8:47, c(4:4)]
##We use the residuals to fit a variogram to check for the spatial dependency
res.geoSH <- as.geodata(cbind(alex_data$Longitude,alex_data$latitude,SHres))
vv <- variog(res.geoSH)
print(plot(vv, type="p",pch=19, col = 2,cex.lab = 1.3,
           ylab = expression(v(u)), lwd = 2 ))  

set.seed(123)
for(i in 1:5000){
  presSh <- sample(SHres)
  pres.geoSh <- as.geodata(cbind(alex_data$Longitude,alex_data$latitude,presSh))
  pvariosh <- variog(pres.geoSh)
  print(lines(pvariosh$u, pvariosh$v, pch = 19, col = "gray"))
}
lines(vv$u, vv$v, pch = 19, col = 2, lwd = 2)
```
Inference on it
